/*
========================================================================================
   AWS Batch Configuration
========================================================================================
*/

process {
    executor = 'awsbatch'
    queue = 'metagenomics-queue'
    
    // Error handling for AWS Batch
    errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
    maxRetries = 3
    
    // Resource labels
    withLabel: 'process_low' {
        cpus = { check_max(2, 'cpus') }
        memory = { check_max(6.GB * task.attempt, 'memory') }
        time = { check_max(4.h * task.attempt, 'time') }
    }
    
    withLabel: 'process_medium' {
        cpus = { check_max(8, 'cpus') }
        memory = { check_max(32.GB * task.attempt, 'memory') }
        time = { check_max(12.h * task.attempt, 'time') }
    }
    
    withLabel: 'process_high' {
        cpus = { check_max(16, 'cpus') }
        memory = { check_max(64.GB * task.attempt, 'memory') }
        time = { check_max(48.h * task.attempt, 'time') }
    }
}

aws {
    region = 'us-east-1'
    batch {
        cliPath = '/home/ec2-user/miniconda/bin/aws'
        maxParallelTransfers = 4
        maxTransferAttempts = 3
    }
    client {
        maxConnections = 20
        connectionTimeout = 10000
        uploadMaxThreads = 4
        uploadChunkSize = 100.MB
        uploadStorageClass = 'INTELLIGENT_TIERING'
        storageEncryption = 'AES256'
    }
}

// Use Docker images (AWS Batch runs Docker natively)
docker {
    enabled = true
}
